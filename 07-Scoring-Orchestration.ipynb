{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond the Training...\n",
    "\n",
    "#### Model scoring, online learning, and workflow orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction / Inference / Scoring\n",
    "\n",
    "In the ML context, these terms all refer to using models to make predictions \n",
    "\n",
    "There are several patterns\n",
    "* Batch (bulk) scoring\n",
    "* Request/response\n",
    "* Streaming\n",
    "\n",
    "In the general case, these are -- happily -- trivially parallelizable and scalable\n",
    "\n",
    "As we move to newer tools, we notice that they are all able to address these use cases.\n",
    "* Ray includes a subproject called Ray Serve \n",
    "    * https://docs.ray.io/en/master/serve/\n",
    "* Dask has various examples addressing these use cases\n",
    "    * https://examples.dask.org/machine-learning/parallel-prediction.html\n",
    "    * https://examples.dask.org/machine-learning/torch-prediction.html\n",
    "    * https://examples.dask.org/applications/async-web-server.html\n",
    "    \n",
    "And we should include the most promising open-source \"ML platform\", Kubeflow https://www.kubeflow.org/\n",
    "\n",
    "__However__ one of the biggest challenges is not over- or under- architecting a model serving solution.\n",
    "* Dask is ideal for batch prediction\n",
    "* But for request-response model serving, one might argue that both Dask and Ray are overly complex relative to the functionality they offer\n",
    "* Kubeflow is complex, but has a broader set of functionality \n",
    "    * ... which may make it worthwhile *if you need that functionality*\n",
    "* For streaming prediction, a simple Kafka or Pulsar application may be sufficient\n",
    "\n",
    "Keep in mind that the fundamental scoring (prediction) operation is typically uncomplicated and does not warrant any \"special\" software system. So if you are going to use or build a larger system, make sure it is meeting, while not exceeding, your actual data management needs.\n",
    "\n",
    "### Model Serving is Trivial; Model Management in Production May Not Be\n",
    "\n",
    "Why might you want a more complex system?\n",
    "* Model performance monitoring\n",
    "* Caching layer\n",
    "* Model drift\n",
    "* A/B or bandit testing\n",
    "* Rolling deploy of new model versions\n",
    "etc.\n",
    "\n",
    "Those concerns are beyond our scope here, but the key point is that your focus as a system designer should be on accommodating those first -- if you need them; I would advise against using an overly complex tool for model serving and then having to bolt on those additional capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Orchestration\n",
    "\n",
    "Apache Airflow, the incumbent orchestration solution, is a nice product. \n",
    "\n",
    "For the next generation of architecture -- particular where ML is the goal from the start, rather than just data transformation -- take a look at Prefect (https://www.prefect.io/core)\n",
    "\n",
    "Prefect's argument -- borrowed straight from https://docs.prefect.io/core/getting_started/why-not-airflow.html#overview -- is:\n",
    "\n",
    ">Airflow was designed to run static, slow-moving workflows on a fixed schedule, and it is a great tool for that purpose. Airflow was also the first successful implementation of *workflows-as-code*, a useful and flexible paradigm. It proved that workflows could be built without resorting to config files or obtuse DAG definitions.\n",
    ">\n",
    "> However, because of the types of workflows it was designed to handle, Airflow exposes a limited \"vocabulary\" for defining workflow behavior, especially by modern standards. Users often get into trouble by forcing their use cases to fit into Airflow's model. A sampling of examples that Airflow can not satisfy in a first-class way includes:\n",
    "> \n",
    "> -   DAGs which need to be run off-schedule or with no schedule at all\n",
    "> -   DAGs that run concurrently with the same start time\n",
    "> -   DAGs with complicated branching logic\n",
    "> -   DAGs with many fast tasks\n",
    "> -   DAGs which rely on the exchange of data\n",
    "> -   Parametrized DAGs\n",
    "> -   Dynamic DAGs\n",
    ">\n",
    "> If your use case resembles any of these, you will need to work *around* Airflow's abstractions rather than *with* them. For this reason, almost every medium-to-large company using Airflow ends up writing a custom DSL or maintaining significant proprietary plugins to support its internal needs. This makes upgrading difficult and dramatically increases the maintenance burden when anything breaks.\n",
    "\n",
    "Naturally, a project's own pitch is not a neutral argument to use that tool -- and I'm not suggesting you take it as such.\n",
    "\n",
    "It is, however, well worth consideration in your system design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
