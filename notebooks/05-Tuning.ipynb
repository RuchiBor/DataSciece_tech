{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning (Hyperparameter Optimization)\n",
    "\n",
    "Although it doesn't appear in our high-level outline diagram, __model tuning__ is the next critical step in a typical data-to-deployment ML flow.\n",
    "\n",
    "Tuning can take many forms\n",
    "* Choosing regularization within a narrow family of models\n",
    "    * L1 and L2 components (\"ElasticNet\") applied to a linear model\n",
    "    * Number of trees or max tree depth in a tree ensemble like random forest or gradient-boosted trees\n",
    "* Adjusting a a parameter which alters the modeling family significantly\n",
    "    * Polynomial order in polynomial regression\n",
    "    * Kernel choice in kernelized SVMs\n",
    "* Architecture search\n",
    "    * Layer type and size in a neural network\n",
    "\n",
    "... and more, depending on the assumptions of the team and tools.\n",
    "\n",
    "While early tuning approaches used grid search (searching a grid of \"points in hyperparam space\" to find the best performing model) or random search (within hyperparam space), more recent libraries have expanded accessibility to sophisticated tuning approaches including\n",
    "* Hyperband (a bandit-based approach)\n",
    "* Bayesian\n",
    "* Population based\n",
    "and more.\n",
    "\n",
    "This has, in turn, spawned frameworks, like Optuna and HyperOpt to encapsulate these techniques.\n",
    "\n",
    "## Tuning is easy ... and hard\n",
    "\n",
    "Computationally, most tuning approaches are embarrasingly parallel operations. This means that they can be fairly easily scaled to many experiments in parallel, taking advantage of large-scale compute to get results quickly.\n",
    "\n",
    "At the same time, as model and tuning complexity increase, there is a rise in value for tooling that can manage, track, and automate this tuning.\n",
    "\n",
    "## Dask and Ray\n",
    "\n",
    "Dask supports a number of approaches to tuning as described here: https://ml.dask.org/hyper-parameter-search.html\n",
    "\n",
    "The Dask approach is most valuable to users who want to get their hands on the pipeline and programmatically manage model training and hyperparam search.\n",
    "\n",
    "Ray takes a slightly different angle: as we saw with Ray RLlib, which encapsulates training use cases into a high-level interface, Ray prominently features a similar tuning library: __Ray Tune__ (https://docs.ray.io/en/latest/tune/)\n",
    "\n",
    "This example -- from the Ray project documentation -- shows the high-level structure/flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "def objective(step, alpha, beta):\n",
    "    return (0.1 + alpha * step / 100)**(-1) + beta * 0.1\n",
    "\n",
    "def training_function(config):\n",
    "    # Hyperparameters\n",
    "    alpha, beta = config[\"alpha\"], config[\"beta\"]\n",
    "    for step in range(10):\n",
    "        # Iterative training function - can be any arbitrary training procedure.\n",
    "        intermediate_score = objective(step, alpha, beta)\n",
    "        # Feed the score back back to Tune.\n",
    "        tune.report(mean_loss=intermediate_score)\n",
    "\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        \"alpha\": tune.grid_search([0.001, 0.01, 0.1]),\n",
    "        \"beta\": tune.choice([1, 2, 3])\n",
    "    })\n",
    "\n",
    "print(\"Best config: \", analysis.get_best_config(\n",
    "    metric=\"mean_loss\", mode=\"min\"))\n",
    "\n",
    "# Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see a more realistic example in the lab, but the key point here is that Ray Tune exposes a meta-API over the underlying algorithms, so that we can more quickly and simply scale lots of experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
